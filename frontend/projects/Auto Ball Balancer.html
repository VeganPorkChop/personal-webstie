<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>2-DoF Ball Balancer Project</title>

  <style>
    :root{
      --bg:#ffffff;
      --text:#111827;
      --muted:#6b7280;
      --card:#e6ebef;
      --border:#c6cad2;
      --accent:#2563eb;

      --code-bg:#0b1020;
      --code-text:#e5e7eb;

      --max: 980px;
      --radius: 14px;
    }

    *{ box-sizing:border-box; }
    body{
      margin:30px 0 0;
      font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji","Segoe UI Emoji";
      color:var(--text);
      background:var(--bg);
      line-height:1.6;
    }

    a{ color:var(--accent); text-decoration:none; }
    a:hover{ text-decoration:underline; }

    .container{
      max-width: var(--max);
      margin: 0 auto;
      padding: 28px 18px 60px;
    }

    header{
      text-align:center;
      padding: 10px 0 14px;
    }
    header h1{
      margin: 10px 0 6px;
      font-size: clamp(2rem, 4vw, 2.8rem);
      letter-spacing: -0.02em;
    }
    header p{
      margin: 0 auto;
      max-width: 75ch;
      color: var(--muted);
      font-size: 1.05rem;
    }

    h2{
      margin: 18px 0 0px;
      font-size: 1.6rem;
      letter-spacing: -0.01em;
    }
    h3{
      margin: 18px 0 8px;
      font-size: 1.2rem;
    }
    h4{
      margin: 14px 0 6px;
      font-size: 1.05rem;
    }

    .card{
      background: var(--card);
      border: 1px solid var(--border);
      border-radius: var(--radius);
      padding: 18px;
      margin: 18px 0;
    }

    .grid{
      display: grid;
      gap: 14px;
    }
    @media (min-width: 860px){
      .grid.two{ grid-template-columns: 1fr 1fr; }
    }

    ul, ol{
      margin: 8px 0 0 1.1rem;
      padding: 0;
    }
    li{ margin: 8px 0; }
    .muted{ color: var(--muted); }

    /* Media */
    figure{
      margin: 14px auto;
      text-align: center;
    }
    figure img{
      max-width: 100%;
      height: auto;
      border-radius: 12px;
      border: 1px solid var(--border);
      background: #fff;
    }
    figcaption{
      margin-top: 8px;
      color: var(--muted);
      font-size: 0.95rem;
    }

    /* Tables */
    table{
      width: 100%;
      border-collapse: collapse;
      margin-top: 10px;
      background: #fff;
      border: 1px solid var(--border);
      border-radius: 12px;
      overflow: hidden;
    }
    th, td{
      border-bottom: 1px solid var(--border);
      padding: 10px 12px;
      text-align: left;
      vertical-align: top;
      font-size: 0.98rem;
    }
    th{
      background: #f3f4f6;
      font-weight: 700;
    }
    tr:last-child td{ border-bottom: none; }

    /* Callouts */
    .callout{
      border-left: 4px solid var(--accent);
      background: #eff6ff;
      padding: 12px 14px;
      border-radius: 12px;
      margin: 12px 0 0;
    }
    .callout strong{ display:inline-block; margin-bottom: 4px; }

    /* Details / Code blocks */
    details{
      border: 1px solid var(--border);
      border-radius: 12px;
      background: #fff;
      padding: 10px 12px;
      margin-top: 12px;
    }
    details > summary{
      cursor: pointer;
      font-weight: 700;
      list-style: none;
    }
    details > summary::-webkit-details-marker { display:none; }

    details.code pre{
      background: var(--code-bg);
      color: var(--code-text);
      border: 1px solid rgba(255,255,255,0.08);
      border-radius: 12px;
      padding: 14px;
      overflow-x: auto;
      margin: 10px 0 0;
    }
    pre code{
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      white-space: pre;
      display: inline-block;
      min-width: 100%;
    }

    .media-stack img{
      display:block;
      margin: 10px auto;
      max-width: 100%;
      border-radius: 12px;
      border: 1px solid var(--border);
      background: #fff;
    }

    footer{
      margin-top: 40px;
      padding-top: 20px;
      border-top: 1px solid var(--border);
      color: var(--muted);
      font-size: 0.95rem;
    }
    code{
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono","Courier New", monospace;
      font-size: 0.95em;
    }

    .top-nav {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            display: flex;
            justify-content: center;
            gap: 20px;
            padding: 12px 0;
            background-color: rgba(255, 255, 255, 0.95);
            z-index: 1000;
            box-shadow: 0 2px 6px rgba(0, 0, 0, 0.15);
        }

        .top-nav a {
            text-decoration: none;
            color: #111;
            font-size: 1rem;
            font-weight: 600;
            display: inline-flex;
            align-items: center;
            justify-content: center;
            border: 2px solid #111;
            border-radius: 999px;
            padding: 6px 18px;
            transition: all 0.3s ease;
        }

        .top-nav a:hover {
            background-color: #111;
            color: #fff;
        }

  </style>
</head>
<body>
  <nav class="top-nav">
        <a href="../frontpage.html">Home</a>
        <a href="../projectoverview.html">Projects</a>
        <a href="../contact.html">Contact</a>
    </nav>
  <div class="container">

    <header>
      <h1>2-DoF Ball Balancer</h1>
      <p>
        A camera-tracked ball-balancing platform built on a Raspberry Pi, using PID control to stabilize the ball in real time.
      </p>
    </header>

    <!-- PLANNING -->
    <section class="card">
      <h2>Planning</h2>

      <div class="grid two">
        <div>
          <h3>Goal</h3>
          <p><strong>Success Statement:</strong> Create a working 2-DoF ball balancer, similar to
            <a href="https://www.youtube.com/watch?v=uRQepbnxg7w" target="_blank" rel="noopener noreferrer">this video</a>,
            using PID control to optimize balancing.
          </p>

          <h4>Criteria</h4>
          <ul>
            <li>Use PID control</li>
            <li>Balance the ball</li>
          </ul>
        </div>

        <div>
          <h3>Constraints</h3>
          <ul>
            <li>We needed camera-based tracking (other sensors/alternatives were too expensive).</li>
            <li>We did not want to use kinematics to control the plate.</li>
            <li>We didn’t have a camera that could connect directly to an Arduino, so we learned Raspberry Pi.</li>
          </ul>

          <h3>Potential Problems</h3>
          <ul>
            <li>Raspberry Pi Zero might not run fast enough.</li>
            <li>Image recognition would be difficult to tune.</li>
            <li>Time constraints were tight for a project of this difficulty.</li>
            <li>A single servo per axis might not be fast/strong enough.</li>
          </ul>
        </div>
      </div>

      <h3>Timeline</h3>
      <table>
        <thead>
          <tr>
            <th>Phase</th>
            <th>Dates</th>
            <th>Primary Goals</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td><strong>Research</strong></td>
            <td>4/19 – 4/24</td>
            <td>Finish research</td>
          </tr>
          <tr>
            <td><strong>Design</strong></td>
            <td>4/24 – 5/5</td>
            <td>Kaz finishes CAD and assembles</td>
          </tr>
          <tr>
            <td><strong>Coding</strong></td>
            <td>4/24 – 5/5</td>
            <td>Graham finishes prototype code and begins debugging</td>
          </tr>
          <tr>
            <td><strong>Documenting</strong></td>
            <td>4/19 – 5/19</td>
            <td>Complete detailed documentation (reflection + required parts)</td>
          </tr>
        </tbody>
      </table>

      <details>
        <summary>Materials</summary>
        <ul>
          <li>Acrylic</li>
          <li>2 servos</li>
          <li>Raspberry Pi</li>
          <li>Switch</li>
          <li>LED</li>
          <li>Breadboard</li>
          <li>M–F aluminum standoffs</li>
          <li>Pi Cobbler</li>
          <li>Keyboard</li>
          <li>Mouse</li>
          <li>Monitor</li>
        </ul>
      </details>

      <h3>Weekly Updates</h3>
      <ul>
        <li>
          <strong>Week 4/24–4/31</strong>
          <ul>
            <li>Documentation started. Most code worked individually except the PID tuning (conceptually correct, needed tuning).</li>
            <li>Servo centering issue: instead of shifting the PID setpoint, we physically leveled the servo and offset its degrees.</li>
          </ul>
        </li>
        <li>
          <strong>Week 5/1–5</strong>
          <ul>
            <li>System ran end-to-end, but camera detection was inconsistent, causing jitter at the “center.” Goal: finish code and achieve stable balancing.</li>
            <li>Planned “quality of life” attachments and testing other balanceable objects.</li>
            <li>Teacher ordered steel balls for testing.</li>
          </ul>
        </li>
        <li>
          <strong>Week 5/8–13</strong>
          <ul>
            <li>Focus: finish documentation and test code with the steel ball.</li>
            <li>Considered auto PID tuning to reduce manual tuning time.</li>
            <li>Planned a base/enclosure to store everything neatly.</li>
          </ul>
        </li>
        <li>
          <strong>Week 5/15–19</strong>
          <ul>
            <li>Dropped optional features due to end-of-year time pressure.</li>
            <li>Steel balls were too heavy for the servos.</li>
            <li>Completed the base and finalized the project for grading.</li>
          </ul>
        </li>
      </ul>
    </section>

    <!-- CODE -->
    <section class="card">
      <h2>Code</h2>

      <h3>Camera Code & Detection</h3>
      <p class="muted">
        Reference: <a href="http://trevorappleton.blogspot.com/2013/11/python-getting-started-with-opencv.html" target="_blank" rel="noopener noreferrer">OpenCV getting started guide</a>
      </p>

      <details class="code">
        <summary>Camera Code</summary>
        <pre><code class="language-py">import os
import cv2
import math

##Resize with resize command
def resizeImage(img):
    dst = cv2.resize(img,None, fx=0.25, fy=0.25, interpolation = cv2.INTER_LINEAR)
    return dst

##Take image with Raspberry Pi camera
os.system("raspistill -o image.jpg")

##Load image
img = cv2.imread("/home/pi/Desktop/image.jpg")
grey = cv2.imread("/home/pi/Desktop/image.jpg",0) #0 for grayscale

##Run Threshold on image to make it black and white
ret, thresh = cv2.threshold(grey,50,255,cv2.THRESH_BINARY)

##Use houghcircles to determine centre of circle
circles = cv2.HoughCircles(thresh,cv2.cv.CV_HOUGH_GRADIENT,1,75,param1=50,param2=13,minRadius=0,maxRadius=175)
for i in circles[0,:]:
    #draw the outer circle
    cv2.circle(img,(i[0],i[1]),i[2],(0,255,0),2)
    #draw the centre of the circle
    cv2.circle(img,(i[0],i[1]),2,(0,0,255),3)

##Determine co-ordinates for centre of circle
x1 = circles[0][0][0]
y1 = circles[0][0][1]
x2 = circles[0][1][0]
y2 = circles[0][1][1]
##Angle betwen two circles
theta = math.degrees(math.atan((y2-y1)/(x2-x1)))

##print information
print "x1 = ",x1
print "y1 = ",y1
print "x2 = ",x2
print "y2 = ",y2
print theta
print circles

##Resize image
img = resizeImage(img)
thresh = resizeImage(thresh)
##Show Images
cv2.imshow("thresh",thresh)
cv2.imshow("img",img)

cv2.waitKey(0)</code></pre>
        <p class="muted">
          Uses OpenCV circle detection. The original guide includes setup + installation details.
        </p>
      </details>

      <h3>Servo Code</h3>
      <p class="muted">
        Reference: <a href="https://gist.github.com/elktros/384443b57a33f399a4acba76191e0e63" target="_blank" rel="noopener noreferrer">Example servo script</a>
      </p>

      <details class="code">
        <summary>Servo Code</summary>
        <pre><code class="language-py">import RPi.GPIO as GPIO
import time

control = [5,5.5,6,6.5,7,7.5,8,8.5,9,9.5,10]

servo = 22

GPIO.setmode(GPIO.BOARD)

GPIO.setup(servo,GPIO.OUT)
# in servo motor,
# 1ms pulse for 0 degree (LEFT)
# 1.5ms pulse for 90 degree (MIDDLE)
# 2ms pulse for 180 degree (RIGHT)

# so for 50hz, one frequency is 20ms
# duty cycle for 0 degree = (1/20)*100 = 5%
# duty cycle for 90 degree = (1.5/20)*100 = 7.5%
# duty cycle for 180 degree = (2/20)*100 = 10%

p=GPIO.PWM(servo,50)# 50hz frequency

p.start(2.5)# starting duty cycle ( it set the servo to 0 degree )


try:
       while True:
           for x in range(11):
             p.ChangeDutyCycle(control[x])
             time.sleep(0.03)
             print x

           for x in range(9,0,-1):
             p.ChangeDutyCycle(control[x])
             time.sleep(0.03)
             print x

except KeyboardInterrupt:
    GPIO.cleanup()</code></pre>
        <p class="muted">
          Note: This is PWM-based control (duty cycle), not degrees directly.
        </p>
      </details>

      <h3>Camera Recording Code</h3>
      <p class="muted">
        Reference: <a href="https://www.geeksforgeeks.org/saving-operated-video-from-a-webcam-using-opencv/" target="_blank" rel="noopener noreferrer">GeeksforGeeks (OpenCV video)</a>
      </p>

      <details class="code">
        <summary>Recording Code</summary>
        <pre><code class="language-py"># Python program to illustrate 
# saving an operated video

# organize imports
import numpy as np
import cv2

# This will return video from the first webcam on your computer.
cap = cv2.VideoCapture(0)

# Define the codec and create VideoWriter object
fourcc = cv2.VideoWriter_fourcc(*'XVID')
out = cv2.VideoWriter('output.avi', fourcc, 20.0, (640, 480))

# loop runs if capturing has been initialized.
while(True):
    # reads frames from a camera
    # ret checks return at each frame
    ret, frame = cap.read()

    # Converts to HSV color space, OCV reads colors as BGR
    # frame is converted to hsv
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

    # output the frame
    out.write(hsv)

    # The original input frame is shown in the window
    cv2.imshow('Original', frame)

    # The window showing the operated video stream
    cv2.imshow('frame', hsv)

    # Wait for 'a' key to stop the program
    if cv2.waitKey(1) & 0xFF == ord('a'):
        break

# Close the window / Release webcam
cap.release()

# After we release our webcam, we also release the output
out.release()

# De-allocate any associated memory usage
cv2.destroyAllWindows()</code></pre>
      </details>

      <h3>PID Code</h3>
      <p class="muted">
        Reference: <a href="https://pypi.org/project/simple-pid/" target="_blank" rel="noopener noreferrer">simple-pid docs</a>
      </p>

      <details class="code">
        <summary>PID Example</summary>
        <pre><code class="language-py">from simple_pid import PID
pid = PID(1, 0.1, 0.05, setpoint=1)#IMPORTANT

# Assume we have a system we want to control in controlled_system
v = controlled_system.update(0)

while True:
    # Compute new output from the PID according to the systems current value
    control = pid(v)#IMPORTANT

    # Feed the PID output to the system and get its current value
    v = controlled_system.update(control)#IMPORTANT</code></pre>
        <p class="muted">
          Non-functional example (shows the call pattern). The key lines are marked.
        </p>
      </details>

      <h3>Camera Recognition Tuning</h3>
      <details class="code">
        <summary>Tuning Code</summary>
        <pre><code class="language-py">import numpy as np
from picamera import PiCamera
import cv2

kernel = np.ones((5,5),np.uint8)

# Take input from webcam
cap = cv2.VideoCapture(-1)

# Reduce the size of video to 320x240 so rpi can process faster
cap.set(3,160)
cap.set(4,160)

def nothing(x):
    pass

cv2.namedWindow('HueComp')
cv2.namedWindow('SatComp')
cv2.namedWindow('ValComp')
cv2.namedWindow('closing')
cv2.namedWindow('tracking')

cv2.createTrackbar('hmin', 'HueComp',38,179,nothing)
cv2.createTrackbar('hmax', 'HueComp',92,179,nothing)

cv2.createTrackbar('smin', 'SatComp',48,255,nothing)
cv2.createTrackbar('smax', 'SatComp',245,255,nothing)

cv2.createTrackbar('vmin', 'ValComp',176,255,nothing)
cv2.createTrackbar('vmax', 'ValComp',255,255,nothing)

while(1):
    buzz = 0
    _, frame = cap.read()

    hsv = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)
    hue,sat,val = cv2.split(hsv)

    hmn = cv2.getTrackbarPos('hmin','HueComp')
    hmx = cv2.getTrackbarPos('hmax','HueComp')

    smn = cv2.getTrackbarPos('smin','SatComp')
    smx = cv2.getTrackbarPos('smax','SatComp')

    vmn = cv2.getTrackbarPos('vmin','ValComp')
    vmx = cv2.getTrackbarPos('vmax','ValComp')

    hthresh = cv2.inRange(np.array(hue),np.array(hmn),np.array(hmx))
    sthresh = cv2.inRange(np.array(sat),np.array(smn),np.array(smx))
    vthresh = cv2.inRange(np.array(val),np.array(vmn),np.array(vmx))

    tracking = cv2.bitwise_and(hthresh,cv2.bitwise_and(sthresh,vthresh))

    dilation = cv2.dilate(tracking,kernel,iterations = 1)
    closing = cv2.morphologyEx(dilation, cv2.MORPH_CLOSE, kernel)
    closing = cv2.GaussianBlur(closing,(5,5),0)

    circles = cv2.HoughCircles(closing,cv2.HOUGH_GRADIENT,2,240,param1=120,param2=10,minRadius=10,maxRadius=0)

    if circles is not None:
        for i in circles[0,:]:
            print (i[0], i[1])

            if int(round(i[2])) < 30:
                cv2.circle(frame,(int(round(i[0])),int(round(i[1]))),int(round(i[2])),(0,255,0),5)
                cv2.circle(frame,(int(round(i[0])),int(round(i[1]))),2,(0,255,0),10)
            elif int(round(i[2])) > 35:
                cv2.circle(frame,(int(round(i[0])),int(round(i[1]))),int(round(i[2])),(0,0,255),5)
                cv2.circle(frame,(int(round(i[0])),int(round(i[1]))),2,(0,0,255),10)
                buzz = 1

    cv2.imshow('HueComp',hthresh)
    cv2.imshow('SatComp',sthresh)
    cv2.imshow('ValComp',vthresh)
    cv2.imshow('closing',closing)
    cv2.imshow('tracking',frame)

    k = cv2.waitKey(5) & 0xFF
    if k == 27:
        break

cap.release()
cv2.destroyAllWindows()</code></pre>
      </details>

      <h3>Prototype Code</h3>
      <details class="code">
        <summary>Prototype</summary>
        <pre><code class="language-py">import numpy as np
from picamera import PiCamera
import cv2
from simple_pid import PID
from gpiozero import Servo
from time import sleep
from gpiozero.pins.pigpio import PiGPIOFactory
from gpiozero import Device
import math
import subprocess

Xval = 0
Yval = 0
servoOutputX = 0
servoOutputY = 0
Xcenter = 0.075
Ycenter = -0.04
SPX = 80
SPY = 80
subprocess.Popen(["pigpiod"])

kernel = np.ones((5,5),np.uint8)

cap = cv2.VideoCapture(-1)
cap.set(3,SPX*2)
cap.set(4,SPY*2)

def nothing(x):
    pass

cv2.namedWindow('XPID')
cv2.namedWindow('YPID')
cv2.namedWindow('tracking')

cv2.createTrackbar('P', 'XPID',150,200,nothing)
cv2.createTrackbar('I', 'XPID',190,200,nothing)
cv2.createTrackbar('D', 'XPID',170,200,nothing)
cv2.createTrackbar('P', 'YPID',150,200,nothing)
cv2.createTrackbar('I', 'YPID',190,200,nothing)
cv2.createTrackbar('D', 'YPID',170,200,nothing)

Device.pin_factory = PiGPIOFactory()

servoX = Servo(25)
servoY = Servo(21)

pidX = PID(0.0, 0.0, 0.0, setpoint=SPX)
pidX.output_limits = (-0.06, 0.06)
pidY = PID(0.0, 0.0, 0.0, setpoint=SPY)
pidY.output_limits = (-0.06, 0.06)

while(1):
    _, frame = cap.read()

    hsv = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)
    hue,sat,val = cv2.split(hsv)

    hmn = 30
    hmx = 92
    smn = 8
    smx = 136
    vmn = 205
    vmx = 255

    Xp = cv2.getTrackbarPos('P','XPID')
    Xi = cv2.getTrackbarPos('I','XPID')
    Xd = cv2.getTrackbarPos('D','XPID')
    Yp = cv2.getTrackbarPos('P','YPID')
    Yi = cv2.getTrackbarPos('I','YPID')
    Yd = cv2.getTrackbarPos('D','YPID')

    hthresh = cv2.inRange(np.array(hue),np.array(hmn),np.array(hmx))
    sthresh = cv2.inRange(np.array(sat),np.array(smn),np.array(smx))
    vthresh = cv2.inRange(np.array(val),np.array(vmn),np.array(vmx))

    tracking = cv2.bitwise_and(hthresh,cv2.bitwise_and(sthresh,vthresh))

    dilation = cv2.dilate(tracking,kernel,iterations = 1)
    closing = cv2.morphologyEx(dilation, cv2.MORPH_CLOSE, kernel)

    circles = cv2.HoughCircles(closing,cv2.HOUGH_GRADIENT,2,120,param1=120,param2=50,minRadius=10,maxRadius=0)

    if circles is not None:
        for ii in circles[0,:]:
            Xval = ii[0]
            Yval = ii[1]
            cv2.circle(frame,(int(round(ii[0])),int(round(ii[1]))),2,(0,255,0),10)

    XmyP = float(Xp)/1000.0-0.2
    XmyI = float(Xi)/1000.0-0.2
    XmyD = float(Xd)/1000.0-0.2
    YmyP = float(Yp)/1000.0-0.2
    YmyI = float(Yi)/1000.0-0.2
    YmyD = float(Yd)/1000.0-0.2

    if Xval <= (SPX-5) or Xval >= (SPX+5):
        servoOutputX = pidX(Xval)
        servoX.value = servoOutputX + Xcenter
    else:
        servoX.value = Xcenter

    if Yval <= (SPY-5) or Yval >= (SPY+5):
        servoOutputY = pidY(Yval)
        servoY.value = servoOutputY + Ycenter
    else:
        servoY.value = Ycenter

    cv2.imshow('tracking',frame)
    pidX.tunings = (-XmyP,-XmyI,-XmyD)
    pidY.tunings = (-YmyP,-YmyI,-YmyD)

    k = cv2.waitKey(5) & 0xFF
    if k == 27:
        break

cap.release()
cv2.destroyAllWindows()</code></pre>
        <div class="callout">
          <strong>Note</strong>
          <p class="muted" style="margin:0;">
            This prototype includes PID tuning via trackbars and uses output limits around ±0.06.
          </p>
        </div>
      </details>

      <h3>Prototype Videos</h3>
      <div class="media-stack">
        <img src="https://user-images.githubusercontent.com/91289762/234966713-8d4e86ee-c05f-425c-882f-11245f7f868c.gif" alt="Prototype video 1" />
        <img src="https://github.com/VeganPorkChop/Engineering3Q4Project/assets/91289762/bc533349-fce9-4ae9-b79c-b90d916db971" alt="Prototype video 2" />
      </div>
    </section>

    <!-- FINAL CODE -->
    <section class="card">
      <h2>Final Code</h2>

      <!-- IMPORTANT: I preserved the user's original line (camera.start_recording('/home/pi/Videos/penis.h264'))
           but renamed the filename to a professional placeholder. -->
      <details class="code">
        <summary>Final Script</summary>
        <pre><code class="language-py">import numpy as np
import cv2
from simple_pid import PID
from gpiozero import Servo
import time
from picamera import PiCamera
from gpiozero.pins.pigpio import PiGPIOFactory
from gpiozero import Device
import subprocess
import os

#camera = PiCamera()
#camera.start_recording('/home/pi/Videos/recording.h264')

Xval = 0
Yval = 0
servoOutputX = 0
servoOutputY = 0
Xcenter = 0.0
Ycenter = 0.12
SPX = 80
SPY = 80
OutputLimit = .08
PID.sample_time = 10
#subprocess.Popen(["pigpiod"])

kernel = np.ones((5,5),np.uint8)

filename = '/home/pi/Videos/FunctionalVideo.avi'
frames_per_second = 24.0

VIDEO_TYPE = {
    'avi': cv2.VideoWriter_fourcc(*'XVID'),
}

def get_video_type(filename):
    filename, ext = os.path.splitext(filename)
    if ext in VIDEO_TYPE:
      return  VIDEO_TYPE[ext]
    return VIDEO_TYPE['avi']

cap = cv2.VideoCapture(0)
out = cv2.VideoWriter(filename, get_video_type(filename), 25, (SPX*2, SPY*2))

cap.set(3,SPX*2)
cap.set(4,SPY*2)

def nothing(x):
    pass

cv2.namedWindow('PID')

cv2.createTrackbar('P', 'PID',130,500,nothing)
cv2.createTrackbar('I', 'PID',100,500,nothing)
cv2.createTrackbar('D', 'PID',70,500,nothing)
Device.pin_factory = PiGPIOFactory()

servoX = Servo(19)
servoY = Servo(13)

pidX = PID(0.07, 0.05, 0.03, setpoint=SPX)
pidX.output_limits = (-OutputLimit, OutputLimit)
pidY = PID(0.07, 0.05, 0.03, setpoint=SPY)
pidY.output_limits = (-OutputLimit, OutputLimit)

try:
    while(1):
        ret, frame = cap.read()
        out.write(frame)

        hsv = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)
        hue,sat,val = cv2.split(hsv)

        hmn = 49
        hmx = 83

        smn = 48
        smx = 245

        vmn = 95
        vmx = 176

        p = cv2.getTrackbarPos('P','PID')
        i = cv2.getTrackbarPos('I','PID')
        d = cv2.getTrackbarPos('D','PID')

        hthresh = cv2.inRange(np.array(hue),np.array(hmn),np.array(hmx))
        sthresh = cv2.inRange(np.array(sat),np.array(smn),np.array(smx))
        vthresh = cv2.inRange(np.array(val),np.array(vmn),np.array(vmx))

        tracking = cv2.bitwise_and(hthresh,cv2.bitwise_and(sthresh,vthresh))

        dilation = cv2.dilate(tracking,kernel,iterations = 1)
        closing = cv2.morphologyEx(dilation, cv2.MORPH_CLOSE, kernel)
        closing = cv2.GaussianBlur(closing,(5,5),0)

        circles = cv2.HoughCircles(closing,cv2.HOUGH_GRADIENT,2,240,param1=120,param2=10,minRadius=10,maxRadius=0)

        if circles is not None:
            for ii in circles[0,:]:
                Xval = ii[0]
                Yval = ii[1]
                cv2.circle(frame,(int(round(ii[0])),int(round(ii[1]))),2,(0,255,0),10)

        XmyP = float(p)/1000.0
        XmyI = float(i)/1000.0
        XmyD = float(d)/1000.0
        YmyP = float(p)/1000.0
        YmyI = float(i)/1000.0
        YmyD = float(d)/1000.0

        pidX.tunings = (XmyP,XmyI,XmyD)
        pidY.tunings = (YmyP,YmyI,YmyD)

        servoOutputX = -1 * pidX(Xval)
        servoX.value = servoOutputX + Xcenter
        servoOutputY = pidY(Yval)
        servoY.value = servoOutputY + Ycenter

        cv2.imshow('PID',frame)

        print("COORDINATES:", "(",Xval,",",Yval,")")
        k = cv2.waitKey(5) & 0xFF
        if k == 27:
            break

except KeyboardInterrupt:
    pass

cap.release()
out.release()
cv2.destroyAllWindows()</code></pre>
      </details>
    </section>

    <!-- FINAL VIDEO -->
    <section class="card">
      <h2>Final Video</h2>
      <figure>
        <img src="https://github.com/VeganPorkChop/Engineering3Q4Project/assets/91289762/ae9d6a03-25a1-4e1a-895a-247433709c73" alt="Final video clip" />
        <figcaption><em>Captured with the same camera used while image processing.</em></figcaption>
      </figure>
    </section>

    <!-- WIRING -->
    <section class="card">
      <h2>Wiring</h2>
      <figure>
        <img src="https://github.com/VeganPorkChop/Engineering3Q4Project/assets/91289762/23425344-9f4e-4db3-9d18-312931dc9fb8" alt="Wiring diagram / photo" />
        <figcaption>
          Two servos + a button + a switch. The other wires support the camera cable.
          See <a href="https://projects.raspberrypi.org/en/projects/getting-started-with-picamera" target="_blank" rel="noopener noreferrer">Raspberry Pi camera documentation</a>.
        </figcaption>
      </figure>
    </section>

    <!-- CAD -->
    <section class="card">
      <h2>CAD</h2>

      <h3>Design</h3>
      <p>
        There are many clever designs online for controlling a balancing plate (often using more complex linkages for higher precision),
        but we chose the simplest approach: one servo controls X, and the other controls Y.
      </p>

      <figure>
        <img src="https://github.com/VeganPorkChop/Engineering3Q4Project/assets/113209502/b8c0fdc3-cc57-451e-9aa2-f6d77423c023" alt="Example design reference" />
        <figcaption class="muted">Example of more complex plate-control mechanisms.</figcaption>
      </figure>

      <p>
        We originally thought we would need two servos per axis to balance servo weight, but the final design used one servo on each side.
      </p>

      <div class="media-stack">
        <img src="https://github.com/VeganPorkChop/Engineering3Q4Project/assets/113209502/bcc08654-6b73-426a-94b2-0dc8c912cedb" alt="CAD image 1" />
        <img src="https://github.com/VeganPorkChop/Engineering3Q4Project/assets/91289762/93e8217c-e8d2-407a-9175-5b58d45c8249" alt="CAD image 2" />
      </div>

      <h3>Build Images</h3>
      <ul>
        <li>
          <strong>Circuitry</strong>
          <figure>
            <img src="https://github.com/VeganPorkChop/Engineering3Q4Project/assets/91289762/1d50daa9-9097-4605-bed4-56e066fa708a" alt="Circuitry photo" />
          </figure>
        </li>
        <li>
          <strong>Final Project</strong>
          <figure>
            <img src="https://github.com/VeganPorkChop/Engineering3Q4Project/assets/91289762/9d3b1861-9b51-41eb-960c-be7101e23590" alt="Final project photo" />
          </figure>
        </li>
        <li><strong>Final Setup</strong> (see images above)</li>
      </ul>

      <p>
        Final CAD link:
        <a href="https://cvilleschools.onshape.com/documents/2733d03459af870860d20d9e/w/29cc8494b29da55394609a40/e/227d4d17cb9859314779c081?renderMode=0&amp;uiState=645a9a5b1180e771a10bf2bd"
           target="_blank" rel="noopener noreferrer">Onshape CAD</a>
      </p>
    </section>

    <!-- REFLECTION -->
    <section class="card">
      <h2>Reflection</h2>

      <h3>Build Reflection</h3>
      <p>
        The build process was an exercise in “rolling with it.” At one point only two of four servos were working, a bracket was broken,
        and the camera lag was significant—but we still made progress toward balancing.
      </p>
      <p>
        In hindsight, we should have fixed core hardware issues earlier instead of pushing forward with software.
        If we redid the project, we’d stabilize the build first, then tune the PID.
      </p>

      <h3>Code Reflection</h3>
      <p>
        The code performed well overall. The main limitation was camera detection accuracy.
        Higher resolution helped detection but slowed the loop enough that the ball could fall off before the controller corrected.
      </p>
      <p>
        If we rebuilt this project, we’d try offloading image processing to a faster computer to increase frame rate and resolution,
        improving accuracy and responsiveness.
      </p>

      <h3>Look out for…</h3>
      <ul>
        <li>
          <strong>PiGPIO setup:</strong> after restart you may need <code>sudo pigpiod</code>.
          Common error: <code>Can't connect to pigpio at 127.0.0.1(8888)</code>
        </li>
        <li><strong>Lighting sensitivity:</strong> detection depends heavily on lighting; avoid windows or use a consistent background.</li>
        <li><strong>Example code issues:</strong> some online examples have broken imports; the final code is the most reliable starting point.</li>
        <li><strong>Reflections:</strong> reflections confuse detection—avoid acrylic for the plate surface.</li>
        <li><strong>Recording tradeoffs:</strong> OpenCV recording can be awkward; PiCamera limits how many consumers can attach at once.</li>
        <li><strong>Servo output limits:</strong> you may not need huge output ranges; the prototype used roughly ±0.06.</li>
        <li>
          <strong>Camera alignment:</strong> if the camera isn’t centered (supports not perfectly vertical), compensate by adjusting the PID setpoint
          (e.g., <code>PID(kP, kI, kD, setpoint=a)</code>).
        </li>
      </ul>
    </section>

    <footer>
      <span>Project write-up formatted for consistent headings, spacing, and code presentation.</span>
    </footer>

  </div>
</body>
</html>
